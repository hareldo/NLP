{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Assignment2.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN13u3Eogb+r26pXo5esOMl"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"twonK-bsUByl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1600772189506,"user_tz":-180,"elapsed":380323,"user":{"displayName":"הראל דויטש","photoUrl":"","userId":"09096742430035362144"}},"outputId":"ae5582db-8cb1-4812-f77b-8a3d7ae1cdfc"},"source":["\n","try:\n","    import google.colab\n","    IN_COLAB = True\n","except:\n","    IN_COLAB = False\n","\n","if IN_COLAB:\n","    ! wget https://raw.githubusercontent.com/hse-aml/natural-language-processing/master/setup_google_colab.py -O setup_google_colab.py\n","    import setup_google_colab\n","    setup_google_colab.setup_week2()\n","\n","import sys\n","sys.path.append(\"..\")\n","from common.download_utils import download_week2_resources\n","\n","download_week2_resources()\n","\n","%tensorflow_version 1.x\n","import tensorflow as tf\n","import numpy as np\n","import re\n","def read_data(file_path):\n","    tokens = []\n","    tags = []\n","    \n","    tweet_tokens = []\n","    tweet_tags = []\n","    for line in open(file_path, encoding='utf-8'):\n","        line = line.strip()\n","        if not line:\n","            if tweet_tokens:\n","                tokens.append(tweet_tokens)\n","                tags.append(tweet_tags)\n","            tweet_tokens = []\n","            tweet_tags = []\n","        else:\n","            token, tag = line.split()\n","            token, tag = line.split()\n","            if (token.strip().lower().startswith(\"http://\")) or (token.strip().lower().startswith(\"https://\")):\n","              token = \"<URL>\"\n","            elif (token.strip().lower().startswith(\"@\")):\n","              token = \"<USR>\"\n","            # Replace all urls with <URL> token\n","            # Replace all users with <USR> token\n","\n","            \n","            tweet_tokens.append(token)\n","            tweet_tags.append(tag)\n","            \n","    return tokens, tags\n","\n","train_tokens, train_tags = read_data('data/train.txt')\n","validation_tokens, validation_tags = read_data('data/validation.txt')\n","test_tokens, test_tags = read_data('data/test.txt')\n","\n","for i in range(3):\n","    for token, tag in zip(train_tokens[i], train_tags[i]):\n","        print('%s\\t%s' % (token, tag))\n","    print()\n","\n","from collections import defaultdict\n","\n","def build_dict(tokens_or_tags, special_tokens):\n","    \"\"\"\n","        tokens_or_tags: a list of lists of tokens or tags\n","        special_tokens: some special tokens\n","    \"\"\"\n","    # Create a dictionary with default value 0\n","    tok2idx = defaultdict(lambda: 0)\n","    idx2tok = []\n","    \n","    token_or_tag_list = list(set([token_or_tag for tt_list in tokens_or_tags for token_or_tag in tt_list]))\n","    all_tokens = special_tokens + token_or_tag_list\n","    \n","    for i,token in enumerate(all_tokens):\n","      tok2idx[token] = i\n","      idx2tok.append(token)\n","    \n","    return tok2idx, idx2tok\n","\n","special_tokens = ['<UNK>', '<PAD>']\n","special_tags = ['O']\n","\n","# Create dictionaries \n","token2idx, idx2token = build_dict(train_tokens + validation_tokens, special_tokens)\n","tag2idx, idx2tag = build_dict(train_tags, special_tags)\n","\n","def words2idxs(tokens_list):\n","    return [token2idx[word] for word in tokens_list]\n","\n","def tags2idxs(tags_list):\n","    return [tag2idx[tag] for tag in tags_list]\n","\n","def idxs2words(idxs):\n","    return [idx2token[idx] for idx in idxs]\n","\n","def idxs2tags(idxs):\n","    return [idx2tag[idx] for idx in idxs]\n","\n","def batches_generator(batch_size, tokens, tags,\n","                      shuffle=True, allow_smaller_last_batch=True):\n","    \"\"\"Generates padded batches of tokens and tags.\"\"\"\n","    \n","    n_samples = len(tokens)\n","    if shuffle:\n","        order = np.random.permutation(n_samples)\n","    else:\n","        order = np.arange(n_samples)\n","\n","    n_batches = n_samples // batch_size\n","    if allow_smaller_last_batch and n_samples % batch_size:\n","        n_batches += 1\n","\n","    for k in range(n_batches):\n","        batch_start = k * batch_size\n","        batch_end = min((k + 1) * batch_size, n_samples)\n","        current_batch_size = batch_end - batch_start\n","        x_list = []\n","        y_list = []\n","        max_len_token = 0\n","        for idx in order[batch_start: batch_end]:\n","            x_list.append(words2idxs(tokens[idx]))\n","            y_list.append(tags2idxs(tags[idx]))\n","            max_len_token = max(max_len_token, len(tags[idx]))\n","            \n","        # Fill in the data into numpy nd-arrays filled with padding indices.\n","        x = np.ones([current_batch_size, max_len_token], dtype=np.int32) * token2idx['<PAD>']\n","        y = np.ones([current_batch_size, max_len_token], dtype=np.int32) * tag2idx['O']\n","        lengths = np.zeros(current_batch_size, dtype=np.int32)\n","        for n in range(current_batch_size):\n","            utt_len = len(x_list[n])\n","            x[n, :utt_len] = x_list[n]\n","            lengths[n] = utt_len\n","            y[n, :utt_len] = y_list[n]\n","        yield x, y, lengths\n","\n","class BiLSTMModel():\n","    pass\n","\n","def declare_placeholders(self):\n","    \"\"\"Specifies placeholders for the model.\"\"\"\n","\n","    # Placeholders for input and ground truth output.\n","    self.input_batch = tf.placeholder(dtype=tf.int32, shape=[None, None], name='input_batch') \n","    self.ground_truth_tags = tf.placeholder(dtype=tf.int32, shape=[None, None], name='ground_truth_tags')\n","  \n","    # Placeholder for lengths of the sequences.\n","    self.lengths = tf.placeholder(dtype=tf.int32, shape=[None], name='lengths') \n","    \n","    # Placeholder for a dropout keep probability. If we don't feed\n","    # a value for this placeholder, it will be equal to 1.0.\n","    self.dropout_ph = tf.placeholder_with_default(tf.cast(1.0, tf.float32), shape=[])\n","    \n","    # Placeholder for a learning rate (tf.float32).\n","    self.learning_rate_ph = tf.placeholder(dtype=tf.float32, shape=[],name='learning_rate_ph')\n","\n","\n","def build_layers(self, vocabulary_size, embedding_dim, n_hidden_rnn, n_tags):\n","    \"\"\"Specifies bi-LSTM architecture and computes logits for inputs.\"\"\"\n","    \n","    # Create embedding variable (tf.Variable) with dtype tf.float32\n","    initial_embedding_matrix = np.random.randn(vocabulary_size, embedding_dim) / np.sqrt(embedding_dim)\n","    embedding_matrix_variable = tf.Variable(initial_value=initial_embedding_matrix,name=\"embeddings_matrix\",dtype=tf.float32,)\n","    \n","    # Create RNN cells (for example, tf.nn.rnn_cell.BasicLSTMCell) with n_hidden_rnnse number of units \n","    # and dropout (tf.nn.rnn_cell.DropoutWrapper), initializing all *_keep_prob with dropout placeholder.\n","    \"\"\"forward_cell = tf.nn.rnn_cell.LSTMCell(num_units=n_hidden_rnn)\n","    forward_cell=tf.nn.rnn_cell.DropoutWrapper(cell=forward_cell,input_keep_prob=self.dropout_ph,output_keep_prob=self.dropout_ph,state_keep_prob=self.dropout_ph)\n","    backward_cell = tf.nn.rnn_cell.LSTMCell(num_units=n_hidden_rnn)\n","    backward_cell=tf.nn.rnn_cell.DropoutWrapper(cell=backward_cell,input_keep_prob=self.dropout_ph,output_keep_prob=self.dropout_ph,state_keep_prob=self.dropout_ph)\"\"\"\n","\n","    forward_cell =  tf.nn.rnn_cell.DropoutWrapper(tf.nn.rnn_cell.BasicLSTMCell(num_units=n_hidden_rnn),input_keep_prob=self.dropout_ph, output_keep_prob=self.dropout_ph, state_keep_prob=self.dropout_ph)\n","    backward_cell = tf.nn.rnn_cell.DropoutWrapper(tf.nn.rnn_cell.BasicLSTMCell(num_units=n_hidden_rnn),input_keep_prob=self.dropout_ph, output_keep_prob=self.dropout_ph, state_keep_prob=self.dropout_ph)\n","\n","    # Look up embeddings for self.input_batch (tf.nn.embedding_lookup).\n","    # Shape: [batch_size, sequence_len, embedding_dim].\n","    embeddings = tf.nn.embedding_lookup(embedding_matrix_variable,self.input_batch)\n","    \n","    # Pass them through Bidirectional Dynamic RNN (tfvalu.nn.bidirectional_dynamic_rnn).\n","    # Shape: [batch_size, sequence_len, 2 * n_hidden_rnn]. \n","    # Also don't forget to initialize sequence_length as self.lengths and dtype as tf.float32.\n","    (rnn_output_fw, rnn_output_bw), _ =  tf.nn.bidirectional_dynamic_rnn(forward_cell,backward_cell,inputs=embeddings,sequence_length=self.lengths,dtype=tf.float32)\n","    rnn_output = tf.concat([rnn_output_fw, rnn_output_bw], axis=2)\n","\n","    # Dense layer on top.\n","    # Shape: [batch_size, sequence_len, n_tags].   \n","    self.logits = tf.layers.dense(rnn_output, n_tags, activation=None)\n","\n","BiLSTMModel.__build_layers = classmethod(build_layers)\n","\n","def compute_predictions(self):\n","    \"\"\"Transforms logits to probabilities and finds the most probable tags.\"\"\"\n","    \n","    # Create softmax (tf.nn.softmax) function\n","    softmax_output = tf.nn.softmax(self.logits)\n","    \n","    # Use argmax (tf.argmax) to get the most probable tags\n","    # Don't forget to set axis=-1\n","    # otherwise argmax will be calculated in a wrong way\n","    self.predictions = tf.argmax(softmax_output,axis=-1)\n","\n","\n","def compute_loss(self, n_tags, PAD_index):\n","    \"\"\"Computes masked cross-entopy loss with logits.\"\"\"\n","    \n","    # Create cross entropy function function (tf.nn.softmax_cross_entropy_with_logits_v2)\n","    ground_truth_tags_one_hot = tf.one_hot(self.ground_truth_tags, n_tags)\n","    loss_tensor =  tf.nn.softmax_cross_entropy_with_logits_v2(ground_truth_tags_one_hot,self.logits)\n","    \n","    mask = tf.cast(tf.not_equal(self.input_batch, PAD_index), tf.float32)\n","    # Create loss function which doesn't operate with <PAD> tokens (tf.reduce_mean)\n","    # Be careful that the argument of tf.reduce_mean should be\n","    # multiplication of mask and loss_tensor.\n","    self.loss =  tf.reduce_mean(tf.multiply(mask,loss_tensor))\n","\n","def perform_optimization(self):\n","    \"\"\"Specifies the optimizer and train_op for the model.\"\"\"\n","    \n","    # Create an optimizer (tf.train.AdamOptimizer)\n","    self.optimizer =  tf.train.AdamOptimizer(learning_rate=self.learning_rate_ph)\n","    self.grads_and_vars = self.optimizer.compute_gradients(self.loss)\n","    \n","    # Gradient clipping (tf.clip_by_norm) for self.grads_and_vars\n","    # Pay attention that you need to apply this operation only for gradients \n","    # because self.grads_and_vars also contains variables.\n","    # list comprehension might be useful in this case.\n","    clip_norm = tf.cast(1.0, tf.float32)\n","    self.grads_and_vars =  [(None, var) if grad is None else (tf.clip_by_norm(grad, clip_norm), var) for grad, var in self.grads_and_vars] \n","    \n","    self.train_op = self.optimizer.apply_gradients(self.grads_and_vars)\n","\n","\n","def init_model(self, vocabulary_size, n_tags, embedding_dim, n_hidden_rnn, PAD_index):\n","    self.__declare_placeholders()\n","    self.__build_layers(vocabulary_size, embedding_dim, n_hidden_rnn, n_tags)\n","    self.__compute_predictions()\n","    self.__compute_loss(n_tags, PAD_index)\n","    self.__perform_optimization()\n","\n","\n","def train_on_batch(self, session, x_batch, y_batch, lengths, learning_rate, dropout_keep_probability):\n","    feed_dict = {self.input_batch: x_batch,\n","                 self.ground_truth_tags: y_batch,\n","                 self.learning_rate_ph: learning_rate,\n","                 self.dropout_ph: dropout_keep_probability,\n","                 self.lengths: lengths}\n","    \n","    session.run(self.train_op, feed_dict=feed_dict)\n","\n","\n","def predict_for_batch(self, session, x_batch, lengths):\n","    feed_dict={self.input_batch: x_batch,\n","               self.lengths: lengths\n","               }\n","    predictions=session.run(self.predictions,feed_dict=feed_dict)\n","    return predictions\n","\n","BiLSTMModel.__declare_placeholders = classmethod(declare_placeholders)\n","BiLSTMModel.__compute_predictions = classmethod(compute_predictions)\n","BiLSTMModel.__compute_loss = classmethod(compute_loss)\n","BiLSTMModel.__perform_optimization = classmethod(perform_optimization)\n","BiLSTMModel.__init__ = classmethod(init_model)\n","BiLSTMModel.train_on_batch = classmethod(train_on_batch)\n","BiLSTMModel.predict_for_batch = classmethod(predict_for_batch)\n","\n","from evaluation import precision_recall_f1\n","\n","def predict_tags(model, session, token_idxs_batch, lengths):\n","    \"\"\"Performs predictions and transforms indices to tokens and tags.\"\"\"\n","    \n","    tag_idxs_batch = model.predict_for_batch(session, token_idxs_batch, lengths)\n","    \n","    tags_batch, tokens_batch = [], []\n","    for tag_idxs, token_idxs in zip(tag_idxs_batch, token_idxs_batch):\n","        tags, tokens = [], []\n","        for tag_idx, token_idx in zip(tag_idxs, token_idxs):\n","            tags.append(idx2tag[tag_idx])\n","            tokens.append(idx2token[token_idx])\n","        tags_batch.append(tags)\n","        tokens_batch.append(tokens)\n","    return tags_batch, tokens_batch\n","    \n","    \n","def eval_conll(model, session, tokens, tags, short_report=True):\n","    \"\"\"Computes NER quality measures using CONLL shared task script.\"\"\"\n","    \n","    y_true, y_pred = [], []\n","    for x_batch, y_batch, lengths in batches_generator(1, tokens, tags):\n","        tags_batch, tokens_batch = predict_tags(model, session, x_batch, lengths)\n","        if len(x_batch[0]) != len(tags_batch[0]):\n","            raise Exception(\"Incorrect length of prediction for the input, \"\n","                            \"expected length: %i, got: %i\" % (len(x_batch[0]), len(tags_batch[0])))\n","        predicted_tags = []\n","        ground_truth_tags = []\n","        for gt_tag_idx, pred_tag, token in zip(y_batch[0], tags_batch[0], tokens_batch[0]): \n","            if token != '<PAD>':\n","                ground_truth_tags.append(idx2tag[gt_tag_idx])\n","                predicted_tags.append(pred_tag)\n","\n","        # We extend every prediction and ground truth sequence with 'O' tag\n","        # to indicate a possible end of entity.\n","        y_true.extend(ground_truth_tags + ['O'])\n","        y_pred.extend(predicted_tags + ['O'])\n","        \n","    results = precision_recall_f1(y_true, y_pred, print_results=True, short_report=short_report)\n","    return results\n","\n","tf.reset_default_graph()\n","\n","model = BiLSTMModel(len(idx2token),len(idx2tag),200,200,token2idx['<PAD>'])\n","\n","batch_size = 32\n","n_epochs = 4\n","learning_rate = 0.005\n","learning_rate_decay = np.sqrt(2)\n","dropout_keep_probability = 0.9\n","\n","sess = tf.Session()\n","sess.run(tf.global_variables_initializer())\n","\n","print('Start training... \\n')\n","for epoch in range(n_epochs):\n","    # For each epoch evaluate the model on train and validation data\n","    print('-' * 20 + ' Epoch {} '.format(epoch+1) + 'of {} '.format(n_epochs) + '-' * 20)\n","    print('Train data evaluation:')\n","    eval_conll(model, sess, train_tokens, train_tags, short_report=True)\n","    print('Validation data evaluation:')\n","    eval_conll(model, sess, validation_tokens, validation_tags, short_report=True)\n","    \n","    # Train the model\n","    for x_batch, y_batch, lengths in batches_generator(batch_size, train_tokens, train_tags):\n","        model.train_on_batch(sess, x_batch, y_batch, lengths, learning_rate, dropout_keep_probability)\n","        \n","    # Decaying the learning rate\n","    learning_rate = learning_rate / learning_rate_decay\n","    \n","print('...training finished.')\n","\n","print('-' * 20 + ' Train set quality: ' + '-' * 20)\n","train_results = eval_conll(model, sess, train_tokens, train_tags, short_report=False)\n","\n","print('-' * 20 + ' Validation set quality: ' + '-' * 20)\n","validation_results = eval_conll(model, sess, validation_tokens, validation_tags, short_report=False)\n","\n","print('-' * 20 + ' Test set quality: ' + '-' * 20)\n","test_results = eval_conll(model, sess, test_tokens, test_tags, short_report=False)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["--2020-09-22 10:52:05--  https://raw.githubusercontent.com/hse-aml/natural-language-processing/master/setup_google_colab.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1939 (1.9K) [text/plain]\n","Saving to: ‘setup_google_colab.py’\n","\n","setup_google_colab. 100%[===================>]   1.89K  --.-KB/s    in 0s      \n","\n","2020-09-22 10:52:05 (26.5 MB/s) - ‘setup_google_colab.py’ saved [1939/1939]\n","\n","File data/train.txt is already downloaded.\n","File data/validation.txt is already downloaded.\n","File data/test.txt is already downloaded.\n","RT\tO\n","<USR>\tO\n",":\tO\n","Online\tO\n","ticket\tO\n","sales\tO\n","for\tO\n","Ghostland\tB-musicartist\n","Observatory\tI-musicartist\n","extended\tO\n","until\tO\n","6\tO\n","PM\tO\n","EST\tO\n","due\tO\n","to\tO\n","high\tO\n","demand\tO\n",".\tO\n","Get\tO\n","them\tO\n","before\tO\n","they\tO\n","sell\tO\n","out\tO\n","...\tO\n","\n","Apple\tB-product\n","MacBook\tI-product\n","Pro\tI-product\n","A1278\tI-product\n","13.3\tI-product\n","\"\tI-product\n","Laptop\tI-product\n","-\tI-product\n","MD101LL/A\tI-product\n","(\tO\n","June\tO\n",",\tO\n","2012\tO\n",")\tO\n","-\tO\n","Full\tO\n","read\tO\n","by\tO\n","eBay\tB-company\n","<URL>\tO\n","<URL>\tO\n","\n","Happy\tO\n","Birthday\tO\n","<USR>\tO\n","!\tO\n","May\tO\n","Allah\tB-person\n","s.w.t\tO\n","bless\tO\n","you\tO\n","with\tO\n","goodness\tO\n","and\tO\n","happiness\tO\n",".\tO\n","\n","Start training... \n","\n","-------------------- Epoch 1 of 4 --------------------\n","Train data evaluation:\n","processed 105778 tokens with 4489 phrases; found: 72166 phrases; correct: 181.\n","\n","precision:  0.25%; recall:  4.03%; F1:  0.47\n","\n","Validation data evaluation:\n","processed 12836 tokens with 537 phrases; found: 8676 phrases; correct: 19.\n","\n","precision:  0.22%; recall:  3.54%; F1:  0.41\n","\n","-------------------- Epoch 2 of 4 --------------------\n","Train data evaluation:\n","processed 105778 tokens with 4489 phrases; found: 3556 phrases; correct: 1064.\n","\n","precision:  29.92%; recall:  23.70%; F1:  26.45\n","\n","Validation data evaluation:\n","processed 12836 tokens with 537 phrases; found: 258 phrases; correct: 85.\n","\n","precision:  32.95%; recall:  15.83%; F1:  21.38\n","\n","-------------------- Epoch 3 of 4 --------------------\n","Train data evaluation:\n","processed 105778 tokens with 4489 phrases; found: 4867 phrases; correct: 2773.\n","\n","precision:  56.98%; recall:  61.77%; F1:  59.28\n","\n","Validation data evaluation:\n","processed 12836 tokens with 537 phrases; found: 398 phrases; correct: 174.\n","\n","precision:  43.72%; recall:  32.40%; F1:  37.22\n","\n","-------------------- Epoch 4 of 4 --------------------\n","Train data evaluation:\n","processed 105778 tokens with 4489 phrases; found: 4632 phrases; correct: 3458.\n","\n","precision:  74.65%; recall:  77.03%; F1:  75.83\n","\n","Validation data evaluation:\n","processed 12836 tokens with 537 phrases; found: 382 phrases; correct: 187.\n","\n","precision:  48.95%; recall:  34.82%; F1:  40.70\n","\n","...training finished.\n","-------------------- Train set quality: --------------------\n","processed 105778 tokens with 4489 phrases; found: 4617 phrases; correct: 4061.\n","\n","precision:  87.96%; recall:  90.47%; F1:  89.19\n","\n","\t     company: precision:   88.04%; recall:   95.02%; F1:   91.40; predicted:   694\n","\n","\t    facility: precision:   86.44%; recall:   87.26%; F1:   86.85; predicted:   317\n","\n","\t     geo-loc: precision:   90.76%; recall:   97.59%; F1:   94.05; predicted:  1071\n","\n","\t       movie: precision:   48.98%; recall:   35.29%; F1:   41.03; predicted:    49\n","\n","\t musicartist: precision:   78.90%; recall:   74.14%; F1:   76.44; predicted:   218\n","\n","\t       other: precision:   88.75%; recall:   90.62%; F1:   89.67; predicted:   773\n","\n","\t      person: precision:   92.43%; recall:   97.86%; F1:   95.07; predicted:   938\n","\n","\t     product: precision:   86.59%; recall:   89.31%; F1:   87.93; predicted:   328\n","\n","\t  sportsteam: precision:   80.43%; recall:   68.20%; F1:   73.82; predicted:   184\n","\n","\t      tvshow: precision:   51.11%; recall:   39.66%; F1:   44.66; predicted:    45\n","\n","-------------------- Validation set quality: --------------------\n","processed 12836 tokens with 537 phrases; found: 378 phrases; correct: 188.\n","\n","precision:  49.74%; recall:  35.01%; F1:  41.09\n","\n","\t     company: precision:   56.57%; recall:   53.85%; F1:   55.17; predicted:    99\n","\n","\t    facility: precision:   50.00%; recall:   38.24%; F1:   43.33; predicted:    26\n","\n","\t     geo-loc: precision:   66.28%; recall:   50.44%; F1:   57.29; predicted:    86\n","\n","\t       movie: precision:    0.00%; recall:    0.00%; F1:    0.00; predicted:     4\n","\n","\t musicartist: precision:   11.11%; recall:    3.57%; F1:    5.41; predicted:     9\n","\n","\t       other: precision:   36.36%; recall:   29.63%; F1:   32.65; predicted:    66\n","\n","\t      person: precision:   48.33%; recall:   25.89%; F1:   33.72; predicted:    60\n","\n","\t     product: precision:   16.67%; recall:    8.82%; F1:   11.54; predicted:    18\n","\n","\t  sportsteam: precision:   55.56%; recall:   25.00%; F1:   34.48; predicted:     9\n","\n","\t      tvshow: precision:    0.00%; recall:    0.00%; F1:    0.00; predicted:     1\n","\n","-------------------- Test set quality: --------------------\n","processed 13258 tokens with 604 phrases; found: 415 phrases; correct: 223.\n","\n","precision:  53.73%; recall:  36.92%; F1:  43.77\n","\n","\t     company: precision:   53.97%; recall:   40.48%; F1:   46.26; predicted:    63\n","\n","\t    facility: precision:   56.67%; recall:   36.17%; F1:   44.16; predicted:    30\n","\n","\t     geo-loc: precision:   71.31%; recall:   52.73%; F1:   60.63; predicted:   122\n","\n","\t       movie: precision:    0.00%; recall:    0.00%; F1:    0.00; predicted:     2\n","\n","\t musicartist: precision:   20.00%; recall:    3.70%; F1:    6.25; predicted:     5\n","\n","\t       other: precision:   36.56%; recall:   33.01%; F1:   34.69; predicted:    93\n","\n","\t      person: precision:   62.32%; recall:   41.35%; F1:   49.71; predicted:    69\n","\n","\t     product: precision:   23.08%; recall:   10.71%; F1:   14.63; predicted:    13\n","\n","\t  sportsteam: precision:   22.22%; recall:   12.90%; F1:   16.33; predicted:    18\n","\n","\t      tvshow: precision:    0.00%; recall:    0.00%; F1:    0.00; predicted:     0\n","\n"],"name":"stdout"}]}]}